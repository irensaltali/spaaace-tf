# Spaaace Infrastructure

Production-grade, high-availability AWS infrastructure for the Spaaace multiplayer game using Terraform.

## Architecture Overview

This infrastructure implements a **High Availability Architecture** that ensures the game continues even when:
- A container/node crashes
- An EC2 instance fails  
- An entire Availability Zone goes down

```
                                    Internet
                                       |
                                   Route53
                                       |
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 |                                           |
           CloudFront ‚îÄ‚îÄ‚îÄ‚îÄ> S3 (Game Website)              ALB (WebSockets)
                 |                                           |
                 |                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 |                                 |                 |
                 |                              ECS Cluster      Redis (ElastiCache)
                 |                                 |             (Game State)
                 |                          EC2 Nodes (ASG)           |
                 |                                 |                 |
                 |                        Game Server (Node.js) <‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 |                        (Hydrates from Redis)
                 |
```

## Key Features

### üéØ High Availability (The "Game Continues" Architecture)

| Failure Scenario | What Happens | Result |
|-----------------|--------------|--------|
| **Node Down** (container crash) | ECS restarts container, Redis hydrates state | Game resumes in 2-3 seconds |
| **EC2 Down** (instance failure) | ASG replaces instance, ECS reschedules tasks | Game resumes from Redis |
| **AZ Down** (datacenter outage) | ALB routes to healthy AZs, Redis replica promotes | Game continues seamlessly |

### üîß Core Components

1. **ECS Cluster (3 AZs)** - Auto-scaling EC2 nodes across availability zones
2. **ElastiCache Redis (Multi-AZ)** - Game state persistence for crash recovery
3. **ALB with Stickiness** - WebSocket-ready load balancer with session affinity
4. **Capacity Provider** - Seamless scaling and instance management

## Quick Start

### Prerequisites

- AWS CLI configured with credentials
- Terraform >= 1.5.0
- Docker (for building game server image)

### 1. Initialize Terraform

```bash
cd envs/dev
terraform init
```

### 2. Review the plan

```bash
terraform plan
```

### 3. Apply infrastructure

```bash
terraform apply
```

### 4. Build and deploy the game server

```bash
# Get the ECR login token
aws ecr get-login-password --region eu-north-1 | docker login --username AWS --password-stdin $(terraform output -raw ecr_repository_url)

# Build and push the image
cd ../../spaaace
docker build -t spaaace-game .
docker tag spaaace-game:latest $(terraform output -raw ecr_repository_url):latest
docker push $(terraform output -raw ecr_repository_url):latest

# Update the ECS service to deploy
cd ../spaaace-tf/envs/dev
aws ecs update-service --cluster $(terraform output -raw ecs_cluster_name) --service $(terraform output -raw ecs_service_name) --force-new-deployment
```

### 5. Deploy the website

```bash
# Sync the dist folder to S3
aws s3 sync ../../spaaace/dist/ s3://$(terraform output -raw website_bucket_name)/ --delete

# Invalidate CloudFront cache
aws cloudfront create-invalidation --distribution-id $(terraform output -raw cloudfront_distribution_id) --paths "/*"
```

## Project Structure

```
spaaace-tf/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ vpc/           # VPC with 3 AZs, public/private subnets
‚îÇ   ‚îú‚îÄ‚îÄ ecs-cluster/   # ECS cluster with EC2 nodes (Multi-AZ)
‚îÇ   ‚îú‚îÄ‚îÄ ecs-service/   # ECS service and task definitions
‚îÇ   ‚îú‚îÄ‚îÄ alb/           # ALB with WebSocket stickiness
‚îÇ   ‚îú‚îÄ‚îÄ ecr/           # Container Registry
‚îÇ   ‚îú‚îÄ‚îÄ elasticache/   # Redis Multi-AZ for game state
‚îÇ   ‚îú‚îÄ‚îÄ s3-website/    # S3 + CloudFront for static site
‚îÇ   ‚îî‚îÄ‚îÄ route53/       # DNS management
‚îú‚îÄ‚îÄ envs/
‚îÇ   ‚îú‚îÄ‚îÄ dev/           # Development environment
‚îÇ   ‚îú‚îÄ‚îÄ staging/       # Staging environment (future)
‚îÇ   ‚îî‚îÄ‚îÄ prod/          # Production environment (future)
‚îî‚îÄ‚îÄ README.md
```

## Module Details

### VPC Module
- **3 AZs** for high availability
- Public and private subnets across all AZs
- NAT Gateway for outbound traffic from private subnets
- VPC Flow Logs (optional)

### ECS Cluster Module
- EC2-backed (not Fargate) for WebSocket stability
- Auto Scaling Group with Multi-AZ distribution
- Capacity Provider for proper scaling
- Spans 3 availability zones

### ALB Module
- WebSocket-ready with 120s idle timeout
- **Session stickiness enabled** (critical for WebSockets)
- Health checks on `/health` endpoint
- Cross-zone load balancing

### ElastiCache (Redis) Module ‚≠ê
- **Multi-AZ enabled** with automatic failover
- 2 nodes (primary + replica) across different AZs
- AOF persistence for data durability
- Game state survives node crashes

### ECS Service Module
- Auto-scaling based on CPU/Memory
- Circuit breaker with rollback
- CloudWatch logs and alarms
- Redis connection environment variables

### S3 Website Module
- Static website hosting
- CloudFront CDN with OAC (Origin Access Control)
- SPA support (index.html for all routes)

### Route53 Module
- DNS records for game and website
- ACM certificate integration
- Health checks

## High Availability Architecture

### How It Works

```
Normal Operation:
  Player -> ALB -> Node A (AZ 1) [Reads/Writes State to Redis]

Node A Crashes:
  Player Disconnects 
       |
       v
  Client Auto-Reconnecting...
       |
       v
  ALB detects Node A is dead
       |
       v
  Routes to Node B (AZ 2)
       |
       v
  Node B fetches Game State from Redis
       |
       v
  GAME RESUMES
```

### Redis State Management

The game server must implement:

1. **State Serialization**: Periodically save game state to Redis
   ```javascript
   // Key: game_room_{roomId}
   // Value: { snapshot: ..., timestamp: ... }
   ```

2. **Hydration on Startup**: Restore state from Redis when container starts
   ```javascript
   // Pseudo-code
   async onRoomStart(roomId) {
       const savedState = await redis.get(`game_room_${roomId}`);
       if (savedState) {
           this.gameEngine.applySnapshot(savedState);
       }
   }
   ```

See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed implementation guide.

## Environments

### Dev Environment
- **3 AZs** for HA testing (`eu-north-1a`, `eu-north-1b`, `eu-north-1c`)
- Cost-optimized (t3.small, single NAT gateway)
- HTTP only (no SSL certificate)
- Auto-scaling disabled
- Redis with 3-day snapshot retention

### Production Environment (Future)
- 3 AZs with multiple NAT gateways
- HTTPS with ACM certificates
- Auto-scaling enabled
- Redis with encryption and longer retention
- WAF protection

## Terraform Cloud Setup

1. Create organization at https://app.terraform.io
2. Create workspace `spaaace-dev`
3. Configure AWS credentials as environment variables:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
   - `AWS_DEFAULT_REGION`
4. Update `envs/dev/main.tf` to use Terraform Cloud backend

## Domain Setup

1. Register domain `spaaace.online` in Route53 or transfer existing
2. Uncomment Route53 module in `envs/dev/main.tf`
3. Request ACM certificate for the domain
4. Update ALB to use HTTPS
5. Run `terraform apply`

## Monitoring

- CloudWatch Logs for ECS containers
- CloudWatch Metrics for ALB, ECS, and Redis
- CloudWatch Alarms (optional)
- Redis CloudWatch metrics for cache performance

## Cost Estimation (Dev)

| Resource | Monthly Cost |
|----------|-------------|
| t3.small EC2 (1x) | ~$15 |
| ALB | ~$16 |
| NAT Gateway | ~$35 |
| ElastiCache (t4g.micro) | ~$12 |
| Data Transfer | ~$5 |
| CloudFront | ~$5 |
| S3 | ~$1 |
| **Total** | **~$89/month** |

Use spot instances to save ~60% on EC2 costs.

## Troubleshooting

### ECS tasks not starting
Check CloudWatch logs:
```bash
aws logs tail /ecs/spaaace-dev-game --follow
```

### WebSocket connections dropping
- ALB idle timeout is set to 120s (configurable)
- Session stickiness is enabled (required for WebSockets)

### Container health check failing
Ensure the game server implements a `/health` endpoint returning 200 OK

### Redis connection issues
Check security groups allow traffic from ECS to Redis on port 6379

### Game state not persisting
Verify game server code implements Redis serialization/hydration

## Security Notes

- ECS tasks run on private subnets (no direct internet access)
- ALB is in public subnets
- Redis is in private subnets, accessible only from ECS security group
- S3 bucket is private, accessed via CloudFront OAC
- Security groups are minimal and specific

## Implementation Checklist for Game Developers

- [ ] Implement `/health` endpoint in game server
- [ ] Add Redis client library (ioredis or redis)
- [ ] Implement `serialize()` method to save game state
- [ ] Implement state hydration on server startup
- [ ] Configure socket.io-redis adapter (if scaling to multiple nodes)
- [ ] Test crash recovery: kill container, verify game resumes
